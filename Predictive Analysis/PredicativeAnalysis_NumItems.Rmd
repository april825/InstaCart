---
title: "InstaCart Predictive Analysis: Number of Items (Danny)"
author: "April Leclair, Daniel Ochoa, Hoang Anh Thai Vu, Qiuhan Sun"
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "PredictiveAnalysis_HTML_Output") })
output:
  bookdown::tufte_html2:
    number_sections: no
    split_by: none
    toc: no
  bookdown::html_document2:
    number_sections: no
    split_by: none
    toc: no
  bookdown::tufte_handout2:
    latex_engine: xelatex
    number_sections: no
    toc: no
---

```{r echo=FALSE, message=FALSE}
library(tidyverse)
library(xgboost)
library(Ckmeans.1d.dp) # Used for XGradient Boosting visuzalization
```

This file is used to predict what products a user will order next

# Reading In The Data
```{r message=FALSE, warning=FALSE }
orders <- read_csv("../Source/orders_sample40.csv")
order_products <- read_csv("../Source/order_products_sample40.csv")
products <- read_csv("../Source/products.csv")
```

# Preparing the Data

Cleaning the data by changing variable types (maybe move this to seperate file in /DataPrep)
```{r}
orders$eval_set <- as.factor(orders$eval_set)
products$product_name <- as.factor(products$product_name)
```

We are going to want the results of the `train` dataset for predictions later.
```{r}
order_products_train <-
  order_products %>%
  inner_join(orders, by="order_id") %>%
  filter(eval_set == "train")
```

We want to build our model only on the `prior` dataset.
```{r}
order_products <-
  order_products %>%
  inner_join(orders, by="order_id") %>%
  filter(eval_set == "prior")
```


(Maybe move feature engineering to seperate script)
# Feature Engineering: Products

```{r}
prods <- order_products %>%
  arrange(user_id, order_number, product_id) %>%
  group_by(user_id, product_id) %>%
  mutate(product.numTimes = row_number()) %>% #  Number of times this product has appeared so far for this user
  ungroup() %>%
  group_by(product_id) %>%
  summarise(product.orders = n(), # total number of times product was ordered
            product.reorders = sum(reordered), # number of times the product was reordered
            product.firstOrders = sum(product.numTimes == 1), # number of users that have ordered this product
            product.secondOrders = sum(product.numTimes == 2)) # number of users that ordered this product more than once

prods$product.reorderProbability <- prods$product.secondOrders / prods$product.firstOrders
prods$product.avgTimesOrdered <- 1 + prods$product.reorders / prods$product.firstOrders
prods$product.reorderRatio <- prods$product.reorders / prods$product.orders

prods <- prods %>% 
  select(-product.reorders, -product.firstOrders, -product.secondOrders)

```


# Feature Engineering: Users

```{r}
users <- orders %>%
  filter(eval_set == "prior") %>%
  group_by(user_id) %>%
  summarise(user.numOrders = max(order_number),
            user.useInterval = sum(days_since_prior_order, na.rm=TRUE),
            user.avgDaysSincePriorOrder = mean(days_since_prior_order, na.rm=TRUE))
```

```{r}
user_products <- order_products %>%
  group_by(user_id) %>%
  summarise(user.totalProducts = n(),
            user.reorderRatio = sum(reordered == 1) / sum(order_number > 1))
```

```{r}
users <- users %>%
  inner_join(user_products, by="user_id")
```

```{r}
users$user.avgOrderSize = users$user.totalProducts / users$user.numOrders
```

As an intermidatory step we want to gather all of the `train` and `test` orders.
```{r}
users_notPrior <- orders %>%
  filter(eval_set != "prior") %>%
  select(user_id, order_id, eval_set, days_since_prior_order)
```

Let's add the `test` and `train` variables to the users table to be used later for predictions.
```{r}
users <- users %>% inner_join(users_notPrior, by="user_id")
```

```{r}
users
```


# Data: User-Product

```{r}
data <- order_products %>%
  group_by(user_id, product_id) %>% 
  summarise(
    user_product.orders = n(),
    user_product.firstOrder = min(order_number),
    user_product.lastOrder = max(order_number),
    user_product.avgCartPosition = mean(add_to_cart_order))
```

```{r}
data <- data %>% 
  inner_join(prods, by = "product_id") %>%
  inner_join(users, by = "user_id")
```

We join with train dataset reorders to train model in which products are reordered
```{r}
data <- data %>% 
  left_join(order_products_train %>% select(user_id, product_id, reordered), 
            by = c("user_id", "product_id"))
```

```{r}

data
```

# Data: Test and Train

```{r}
train <- data %>%
  ungroup() %>%
  filter(eval_set == "train") %>%
  select(-eval_set, -user_id, -product_id, -order_id)

train$reordered[is.na(train$reordered)] <- 0
```

```{r}
test <- data %>%
  ungroup() %>%
  filter(eval_set == "test") %>%
  select(-eval_set, -user_id, -order_id, -reordered)
```

# Predictions

```{r}
(sampleTrain <- train %>% 
   sample_frac(0.1)) 

#Stole this last part from Kaggle discussions

params <- list(
  "objective"           = "reg:logistic",
  "eval_metric"         = "logloss",
  "eta"                 = 0.1,
  "max_depth"           = 6,
  "min_child_weight"    = 10,
  "gamma"               = 0.70,
  "subsample"           = 0.76,
  "colsample_bytree"    = 0.95,
  "alpha"               = 2e-05,
  "lambda"              = 10
)
```

```{r}
X <- xgb.DMatrix(as.matrix(sampleTrain %>% select(-reordered)), label = sampleTrain$reordered)
model <- xgboost(data = X, params = params, nrounds = 80)
importance <- xgb.importance(colnames(X), model = model)
```

```{r}
xgb.ggplot.importance(importance)
```