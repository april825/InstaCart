---
title: "InstaCart Exploratory Analysis: Products Analysis"
author: "Hoang Anh Thai Vu, Daniel Ochoa, Qiuhan Sun, April Choi"
date: "October 18, 2017"
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "ExploratoryAnalysis_HTML_Output") })
output:
  bookdown::tufte_html2:
    number_sections: no
    split_by: none
    toc: no
  bookdown::html_document2:
    number_sections: no
    split_by: none
    toc: no
  bookdown::tufte_handout2:
    latex_engine: xelatex
    number_sections: no
    toc: no
---

This file provides some exploratory analysis of the InstaCart data products, aisles and departments.

```{r setup, include=FALSE}
library(tufte)
library(tidyverse)
library(ggplot2)
library(scales)
library(reshape2)
library(ggmap)
library(ggdendro)             #for tree plot
library(tint)
library(tree)               #for classification trees
library(caret)              #for confusion matrices
library(e1071)              #to make caret run
library(rpart)              #alternative package to make trees
library(randomForest)       #to make random forests
library(gbm)                #to make gradient boosted trees
library(ape)                #to make hierarchical clusters
library(mclust)             #for k-means clustering
library(BBmisc)             #for data normalization
knitr::opts_chunk$set(tidy = FALSE, message=FALSE, cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
```

# Reading in the data

Instead of sampling, we will use the sample40 data to explore the characteristics of products.

```{r cache=TRUE}
aisles = read_csv("../Source/aisles.csv")
departments = read_csv("../Source/departments.csv")
products = read_csv("../Source/products.csv")
order_products_sample40 = read_csv("../Source/order_products_sample40.csv")
```

# Preparing the data

Merging all product related configure

```{r cache=TRUE}
warehouse <- products%>%
  left_join(departments)%>%
  left_join(aisles)

inventory <- warehouse%>%
  group_by(department,aisle)%>%
  summarise(total=n())%>%
  arrange(desc(total))

orders_details_sample40 <- left_join(order_products_sample40,warehouse)
```

```{r, echo=FALSE}
knitr::kable(
  inventory[1:10,], caption = 'Top 10 Aisles with The Most Variety of Products'
)
```




# Network Analysis for Aisles

In this section, we are going to explore the network of aisles. The goal is to understand if an order of any item in an aisle should result in a suggestion of items in another aisles. We are doing so by seeing how often any pair of aisles appear in the same order. 

First of all, we get a table of only information about order_id and aisle


```{r}
orders_aisles_sample40 <- orders_details_sample40%>%
  select(order_id,aisle)%>%
  distinct(order_id,aisle)
```

Then, we need to create an adjacency matrix `aisle_adjacency` of co-appearance of aisles. Value of `aisle_adjacency[i,j]` indicates how many time aisle \i and \j appear in the same order:

```{r cache=TRUE}
# Convert the table of order_id and aisles_id into an incidence matrix
aisle_incidence=as.matrix(table(cbind.data.frame(order=orders_aisles_sample40$order_id,aisle=c(orders_aisles_sample40$aisle))))
# Multiple with its transpose to create the adjacency matrix for 
aisle_adjacency=t(aisle_incidence)%*%aisle_incidence
```

```{r, echo=FALSE}
knitr::kable(
  aisle_adjacency[1:10,1:10], caption = 'A subset of the adjacency matrix'
)
```

Next, we explore to see which aisles get ordered the most. Here are the top 20 ordered aisles, taking values from the diagonal of the adjacency matrix.

```{r}
aisle_appearance <- melt(diag(aisle_adjacency))
top20_aisle <- aisle_appearance%>%
  mutate(name=factor(row.names(aisle_appearance)))%>%
  select(name,value)%>%
  arrange(desc(value))%>%
  head(n=20)
```

```{r, echo=FALSE}
knitr::kable(
  top20_aisle[,], caption = 'Top 20 Most Ordered Aisles'
)
```

```{r, echo=FALSE}
ggplot(top20_aisle,aes(x=reorder(name,top20_aisle$value),y=value))+
  geom_col(position = "dodge",fill="seagreen4")+
  coord_flip()+
  labs(
    title="Top 20 Most Ordered Aisles",
    y="Orders",
    x="Aisle"
  )
```

Now, we are going to visualize the adjacency matrix with a heat map. The first thing to do is to flatten the adjacency matrix into a table of 3 columns. The first two columns indicate the pair of value in the adjacency matrix (edge), and the third column stores the values of that pair (weigh of an edge)

```{r}
# Flatten the adjacency matrix to a weighted edgelist
aisle_edgelist=melt(aisle_adjacency)
cols <- which(names(aisle_edgelist) == 'aisle')
names(aisle_edgelist)[cols] <- paste0('aisle', seq_along(cols))
```

```{r, echo=FALSE}
knitr::kable(
  aisle_edgelist[1:10,], caption = 'Sample Weighted Edge List'
)
```

We will only visualize the adjacency matrix on the top 20 most ordered aisle

```{r}
# Select the top 20 most ordered aisle using factor
top_aisle_edgelist <- aisle_edgelist%>%
  mutate(
        aisle1 = factor(aisle1, levels = top20_aisle$name),
        aisle2 = factor(aisle2, levels = top20_aisle$name)
        )
# Get rid of NAs
top_aisle_edgelist <- top_aisle_edgelist[complete.cases(top_aisle_edgelist),]
```

```{r, echo=FALSE}
knitr::kable(
  top_aisle_edgelist[1:10,], caption = 'Sample Weighted Edge List for Top 20 Aisle'
)
```

Now, we visualize the adjacency matrix with a heat map using `geom_raster`

```{r, echo=FALSE}
ggplot(top_aisle_edgelist, aes(x = aisle1, y = aisle2, fill = value)) +
  geom_raster() +
  theme_bw(base_size=9)+
  scale_fill_gradientn(colours=c("#FFFFFFFF","#FF0000FF")) +
  guides(fill = guide_colorbar(barwidth = 0.4, barheight = 6))+
  theme(
    # Rotate the x-axis lables so they are legible
    axis.text.x = element_text(angle = 270, hjust = 0),
    # Force the plot into a square aspect ratio
    aspect.ratio = 1,
    #legend.text=element_text(size=0.1)
    )+
  labs(title="Co-appearances of Aisles in An Order",
       subtitle="Top 20 Most Ordered Aisles",
       x="",
       y="",
       fill="Count")
```
 
# Interpretation

We could see from the heatmap that fresh fruits and fresh vegetables are the most ordered aisles from InstaCart. This makes lots of sense since people need these items fresh pretty frequently. We could also see that they often come together, and people don't usually just order these alone. Some other items that often go with the fresh items are `package vegetables fruits`, `yogurt`, `packaged cheese`, and `milk`.

However, one weakness of this heatmap is that the value depends on the diagonal values. If one aisle gets ordered more, then it is quite likely that it would come with some other items. Thus, the next step would be to normalized all these items to see if the frequency change for these aisle. For example, if `fresh fruits` and `soft drinks` have the same total number of orders, which items are they likely to be paired with (or may be just themselves).


## Hierarichal Clustering -- Question: Which Aisles Are More Likely To Be Orderd Together?

# Original Adjacency Matrix

We are going to conduct unsupervised learning on the original adjacency matrix created above to see which aisles are more likely to be ordered together. First, we conducted the `hclust` analysis on the adjacency matrix

```{r}
set.seed(15)
aisle_pairing=data.frame(aisle_adjacency)
aisle_pairing_diffs<-dist(aisle_pairing)
aisle_pairing_hc<-hclust(aisle_pairing_diffs)
```

Then, wer are going to cut the tree into 12 clusters. Here is the Visualization of the result:

```{r, fig.height=12, fig.width=14, out.width='200%'}
cluscut = cutree(aisle_pairing_hc, 12)

mypal=c("#331a1d","#ff80c4","#aa2db3","#5200cc","#acb4e6","#40d9ff","#008077","#003307","#cef2b6","#555916","#cc8800","#ffb380","#f2553d","#f27989","#cc99c2","#2d2040","#7466cc","#2d3e59","#739699","#79f2da","#00ff22","#525943","#d9ce36","#7f6240","#a65b29","#66241a","#8c4662","#4d003d","#330080","#090040","#3385cc","#13494d","#238c4d","#7bd96c","#ccff00","#bfaf8f","#331b00","#cca799")

# Visualization
plot(as.phylo(aisle_pairing_hc),type="radial",tip.color = mypal[cluscut],
     label.offset = 0.1, cex = 1, edge.width = 2)
```

Conclusion: The result is not good enough. We could not interpret anything from that tree!

# Unsupervised Learning -- Normalized Dataset

One of the reason for such bad behaviors in the tree above is because the vectors for each aisle are scaled based on how many times that aisle is ordered. Thus, similar aisles in this case are the aisles that has similar length, which is dominated by the vector length.

A solution to this problem is normalizing the dataset using `normalizing` function, and conduct the same analysis:

```{r, fig.height=12, fig.width=14, out.width='200%'}
aisle_pairing_norm <- normalize(aisle_pairing)
aisle_pairing_ndiffs <- dist(aisle_pairing_norm)
aisle_pairing_nhc<-hclust(aisle_pairing_ndiffs)

# Plot
cluscut = cutree(aisle_pairing_nhc, 12)
plot(as.phylo(aisle_pairing_nhc),type="radial",tip.color = mypal[cluscut],
     label.offset = 0.1, cex = 1, edge.width=2)
```

Interpretation: We could see that the result improves a lot! 

For example, it makes sense that the alcohols are often ordered together, or the hygiene care items, or cleaning products. However, dÃ³e it make much sense for `ice cream toppings` and `ice cream ice` to be separated?

One draw back of this method is that it normalizes the whole data table. Since this is an adjacency matrix, let's try another approach.

# Unsupervised Learning -- Scaling Each Row with Corresponding Diagonal Value

Question: How similar in pairing behaviors for any two aisles?

Since the diagonal values are the total times an aisle gets orderd, we could scale down each row by the corresponding value of the aisle it represents. The result would be the vector recording the percentage of time the row aisle gets paired with any other aisle. The more similar the pairing behaviors of two aisle, the closers their vectors will be. 

We conduct the same analysis

```{r, fig.height=12, fig.width=14, out.width='200%'}
aisle_pairing_diagscale <- aisle_adjacency*(1/diag(aisle_adjacency)) # divide each row with corresponding diagonal value
aisle_pairing_diagscale <- data.frame(aisle_pairing_diagscale)
aisle_pairing_diagdiffs <- dist(aisle_pairing_diagscale)
aisle_pairing_diaghc<-hclust(aisle_pairing_diagdiffs)

# Plot
cluscut = cutree(aisle_pairing_diaghc, k=12)
plot(as.phylo(aisle_pairing_diaghc),type="radial",tip.color = mypal[cluscut],
     label.offset = 0.1, cex = 1, edge.width=2)
```

Interpretation: we have a really interesting result! Just based on the pairing data of the aisles, we could see how similar these aisles are to each other. Most of the grouped item belong in the same department, but not always the case. It seems that these are the similarity in the use case for each aisle, since they would have similar pairing behaviors. Such information would be useful for future recommendation algorithm.

