---
title: "InstaCart Predictive Analysis: Products"
author: "April Leclair, Daniel Ochoa, Hoang Anh Thai Vu, Qiuhan Sun"
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "PredictiveAnalysis_HTML_Output") })
output:
  bookdown::tufte_html2:
    number_sections: no
    split_by: none
    toc: no
  bookdown::html_document2:
    number_sections: no
    split_by: none
    toc: no
  bookdown::tufte_handout2:
    latex_engine: xelatex
    number_sections: no
    toc: no
---



This file provides some exploratory analysis of the InstaCart data products, aisles and departments.

```{r setup, include=FALSE}
library(tufte)
library(tidyverse)
library(ggplot2)
library(scales)
library(reshape2)
library(tree)
library(randomForest)
knitr::opts_chunk$set(tidy = FALSE, message=FALSE, cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
```

# Reading in the data

Instead of sampling, we will use the sample40 data to explore the characteristics of products.

```{r cache=TRUE}
aisles = read_csv("../Source/aisles.csv")
departments = read_csv("../Source/departments.csv")
products = read_csv("../Source/products.csv")
order_products_prior40 <- read_csv("../Source/order_products_sample40.csv") %>%
  subset(select=-X1)
order_products_train <- read_csv("../Source/order_products__train.csv")
orders40 = read_csv("../Source/orders_sample40.csv")
```

# Preparing the data for training

Filtering out only priors data for train subset

```{r}
# Filter out the orders would lead the final evaluation of 'train' (instead of test eval)
train_users <- subset(orders40,eval_set=='train')
orders40 <- orders40%>%
  mutate(order_dow = factor(order_dow, levels=c("Sunday","Monday","Tuesday","Wednesday","Thurday","Friday","Saturday")))
orders40_train <- orders40%>%
  filter(user_id %in% train_users$user_id)
# Prios data for train set
order_products_trprior40 <- subset(order_products_prior40, order_id %in% unique(orders40_train$order_id))
```

Create the testing data from training set

```{r cache=TRUE}
order_products_train40 <- subset(order_products_train, order_id %in% unique(orders40$order_id))

# Remove excess datasets
rm(order_products_train,order_products_prior40,orders40)
```

# Merging all product related configure

```{r cache=TRUE}
warehouse <- products%>%
  left_join(departments)%>%
  left_join(aisles)%>%
  mutate(department=as.factor(department))

inventory <- warehouse%>%
  group_by(department,aisle)%>%
  summarise(total=n())%>%
  arrange(desc(total))

orders_details_trprior40 <- left_join(order_products_trprior40,warehouse)
```

# Choosing one specific user to conduct analysis

We are going to look at the behaviors of one particular user to conduct a predictive analysis on the products he/she would order.

First of all, let's take a look at the users ranked by the number of orders they have made in the sample set. Note that due to the way InstaCart selected these dataset, the number of orders for each user range from 4 to 100. 

```{r cache=TRUE}
top_users <- orders40_train %>%
  group_by(user_id)%>%
  summarise(total_orders=n(),total_days=sum(days_since_prior_order))%>%
  arrange(desc(total_orders))
```

```{r, echo=FALSE}
knitr::kable(
  top_users[1:20,], caption = 'Top 20 Users with Most Orders'
)
```

We are going to look at the first one that showed up: the user with `user_id` of 210.

```{r}
user210_orders <- subset(orders40_train,user_id==210)
user210_products_prior <- subset(order_products_trprior40,order_id %in% user210_orders$order_id)
user210_products_train <- subset(order_products_train40,order_id %in% user210_orders$order_id)  
user210_prior_details <- left_join(user210_products_prior,user210_orders) %>%
  left_join(warehouse)%>%
  select(-X1,-eval_set,-user_id,-aisle_id,-department_id)
```

The table below consists of information about department in each order the User210 made. 

```{r}
user210_prior_department <- user210_prior_details%>%
  select(order_number,department,order_dow,order_hour_of_day,days_since_prior_order)%>%
  group_by(order_number,department,order_dow,order_hour_of_day,days_since_prior_order)%>%
  summarise(count=n())%>%
  group_by(order_number)%>%
  mutate(total=sum(count),percentage=count/total)
```

```{r, echo=FALSE}
knitr::kable(
  user210_prior_department[1:9,], caption = 'User 210 Product Department Summary'
)
```

Since it is likely that a user behavior will be somewhat consistent (habits), we expect the percentage of each department ordered could be predicted based on Day of Week, Hour of Day, and Total amount of Order.

Here is the visualization on the dataset. We could observe that the behaviour is indeed quite consistent and predictable

```{r}
ggplot(user210_prior_department,aes(x=order_dow,y=percentage,color=department))+
  geom_jitter(alpha=0.5)
ggplot(user210_prior_department,aes(x=order_hour_of_day,y=percentage,color=department))+
  geom_jitter(alpha=0.5)
ggplot(user210_prior_department,aes(x=total,y=percentage,color=department))+
  geom_point(alpha=0.5)
```

# Department Predictive Analysis -- Data Prep

First of all, we are going to divide the prior data set into two parts. The first 70 days will be used to train the dataset, and the rest 29 days will be used to test the performance of our prediction.

```{r}
user210_prior_department70 <- user210_prior_department%>%
  subset(order_number<71)%>%
  ungroup
user210_prior_department29 <- user210_prior_department%>%
  subset(70<order_number&order_number<100)%>%
  ungroup
```

# Department Predictive Analysis -- Regression

```{r}
lm1=lm(percentage~order_dow+total+department,user210_prior_department70)
summary(lm1)
```

# Department Predictive Analysis -- Decision Tree

1. Tree of: `percentage~department`

```{r}
set.seed(3)
tree1<-tree(percentage~department,
            data=user210_prior_department70)
summary(tree1)
plot(tree1)
text(tree1,pretty=1)
```

2. Tree of: `percentage~department+total+order_dow`

```{r}
set.seed(30)
tree2<-tree(percentage~department+total+order_dow,
            data=user210_prior_department70)
summary(tree2)
plot(tree2)
text(tree2,pretty=1)
```

# Department Predictive Analysis -- Random Forest

```{r}
set.seed(300)
forest1 <- randomForest(percentage~department,user210_prior_department70)
```

```{r}
set.seed(300)
forest2 <- randomForest(percentage~department+order_dow+total,user210_prior_department70)
```

# Visualization

```{r}
forest.pred <- predict(forest2, user210_prior_department70)    
user210_prior_department70 <- user210_prior_department70 %>% 
    mutate(forest.prediction=forest.pred)    
ggplot(user210_prior_department70, aes(y=forest.prediction, x=order_dow, color=department)) +
    geom_line()+
    geom_jitter(aes(y=percentage, x=order_dow, color=department), alpha=0.5)+
    labs(title="An Example of Order-Department Prediction -- Random Forests")
```

# Testing and Results

```{r}
lmtest <- predict(lm1, user210_prior_department29)
tree1test <- predict(tree1, user210_prior_department29)
tree2test <- predict(tree2, user210_prior_department29) 
forest1test <- predict(forest1, user210_prior_department29) 
forest2test <- predict(forest2, user210_prior_department29)    


TestResults <- user210_prior_department29 %>% 
    mutate(lmtest, tree1test)%>%
    mutate(lmError=(percentage-lmtest), tree1Error=(percentage-tree1test),
           tree2Error=(percentage-tree2test),forest1Error=(percentage-forest1test), forest2Error=(percentage-forest2test))
mean(TestResults$lmError^2) 
mean(TestResults$tree1Error^2) 
mean(TestResults$tree2Error^2)
mean(TestResults$forest1Error^2)
mean(TestResults$forest2Error^2)

```

We could see that all supervised learning model outperformed the linear regression. Surprisingly, the best result we got was from the simple `tree` with only one dependent variable `department`. Adding time component to the model worsen the prediction. 


