---
title: "InstaCart Predictive Analysis: Logit Using `data_final`"
author: "April Leclair, Daniel Ochoa, Hoang Anh Thai Vu, Qiuhan Sun"
date: "December 11, 2017"
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "PredictiveAnalysis_HTML_Output") })
output:
  bookdown::tufte_html2:
    number_sections: no
    split_by: none
    toc: no
  bookdown::html_document2:
    number_sections: no
    split_by: none
    toc: no
  bookdown::tufte_handout2:
    latex_engine: xelatex
    number_sections: no
    toc: no
---

```{r setup, include=FALSE, cache=FALSE}
library(tufte)
library(caret)  # Used for confusion matrix
library(tidyverse)
knitr::opts_chunk$set(tidy = FALSE, message=FALSE, cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
```


# Reading In The Data
```{r message=FALSE, warning=FALSE, echo=FALSE}
trainDF <- read_csv("../Source/trainingData.csv")
# test <- read_csv("../Source/testingData.csv")  # Only to be used when turning in to kaggle competition
products <- read_csv("../Source/products.csv")  # Used to provide product names (hasn't been incorporated yet)
```

Since we don't have the answers to the test dataset we need to partition our training set into training and testing to validate our results and avoid overfitting.
```{r}
set.seed(567) # Used for reproducability of results

inTrain <- sample_frac(data.frame(unique(trainDF$order_id)), 0.7)

train <- trainDF %>%
  filter(order_id %in% inTrain$unique.trainDF.order_id.)
test <- trainDF %>%
  filter(!order_id %in% inTrain$unique.trainDF.order_id.)

rm(trainDF)
rm(inTrain)
```

# Predictive Analysis

## Logistic Regression: Full Model 
Fit the model for binomial regression.
```{r}
modelf <- glm(reordered ~ . - `user_id` - `product_id`, family = binomial(link = 'logit'), data = train)
```

Obtain the results of our model:
```{r}
summary(modelf)
```

We can see that `uid.reorderProducts`, `uid.maxDaysSince`, `uid.aveDow`, `uid.sdDow`, `uid.pantry_distr` & `uid.bakery_distr` are not statistically significant. On the other hand, most other variables are strongly statistically significant (***), while some other variables such as `uid.sdHr`, `uid.snacks_distr` & `uid.frozen_distr` are on the boarderline of statistical significance (*). The variables with the strongest statistical significance (***) or those with the lowest p-values have a strong association with reorder probability.


## Testing function
```{r}
f1_test <- function (pred, ref,user_id) {
  require(ModelMetrics)
  dt <- tibble(user_id, pred, ref)
  dt <- dt %>%
    group_by(user_id)%>%
    mutate(f1_score = f1Score(pred,ref))%>%
    summarise(f1_score = mean(f1_score,na.rm=TRUE))
  f1_mean <- mean(dt$f1_score,na.rm=TRUE)
  message("F1 Score")
  return (f1_mean)
}
```


### Predict & Sensitivity, Specificity, and Accuracy - Comparison
```{r}
pred_logit <- predict(modelf, test, type = 'response')
pred_logit <- ifelse(pred_logit > 0.21, 1, 0)
pred_logit[is.na(pred_logit)] <- 0

pred_null <- ifelse(test$user_product.order_streak > 0, 1, 0)

f1_test(pred_logit, test$reordered, test$user_id)
f1_test(pred_null, test$reordered, test$user_id)
f1_test(pred_logit, test$reordered, test$user_id)-f1_test(pred_null, test$reordered, test$user_id)
```


## Plot GLM
```{r}
ggplot(train, aes(x=user_product.orderRate, y=reordered)) + geom_point() + 
stat_smooth(method="glm", family="binomial", se=TRUE)
```